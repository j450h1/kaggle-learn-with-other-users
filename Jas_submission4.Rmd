---
title: "Jas_submission4"
author: "Jas Sohi"
date: "10/14/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Next with Logistic Regression and top 5 features with basic train test split

```{python}
import pandas as pd
from pathlib import Path
from sklearn.model_selection import train_test_split
```

```{python}
# no need to unzip
test = pd.read_csv(Path.cwd() / "test.csv.zip")
train = pd.read_csv(Path.cwd() / "train.csv.zip")

train.head()
```

```{python}
train.columns
```

# We can actually use ALL train data

```{python}
X = train.drop(['Id', 'Cover_Type'], axis=1)
y = train['Cover_Type']
```

```{python}
X.head()
y.head()
```


# RFECV

* To find the optimal number of features cross-validation is used with RFE to score different feature subsets and select the best scoring collection of features. Cross-validation refers to splitting up your data into multiple train and test sets so you use as much as the data as possible and are able to ensure your results will generalize to new unseen data.

```{python}
from sklearn import linear_model
from sklearn.model_selection import StratifiedKFold #old import got deprecated
from sklearn.feature_selection import RFECV

logreg = linear_model.LogisticRegression()
#Use RFECV to pick best features, using Stratified Kfold
rfecv = RFECV(estimator=logreg, cv=StratifiedKFold(3), scoring='roc_auc')
rfecv
#rfecv.fit(y)
```

```{python}
rfecv.fit(X, y)
```
* Doesn't work with multi-class values

# Select 5 Best Values


```{python}
X.head()
```

```{python}
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import chi2

X_new = SelectKBest(chi2, k=5).fit_transform(X, y)
X_new.shape
```

# Check for negative values in any of the columns

```{python}
for cols in X.columns.tolist()[1:]:
    data = X.loc[X[cols] < 0]
data
```

# Top 3 features now

```{python}
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import f_classif
selector = SelectKBest(f_classif, k=3)
X_new = selector.fit_transform(X, y)
X_new.shape
```

```{python}
# Get columns to keep
cols = selector.get_support(indices=True)
# Create new dataframe with only desired columns, or overwrite existing
cols
X_new_chosen = X.iloc[:, cols]
```
```{python}
X_new_chosen
```

```{python}
X_new_chosen['Soil_Type3'].value_counts()
```

```{python}
X_new_chosen.columns
```

```{python}
# Create local validation
validation_train, validation_test = train_test_split(train, test_size=0.3, random_state=123)
```

```{python}
features_selected = X_new_chosen.columns #x
target = ['Cover_Type'] #y
X_train = validation_train[features_selected]
y_train = validation_train[target]
X_test = validation_test[features_selected]
y_test = validation_test[target] #switch to all 4 in one as shown elsewhere
```

```{python}
from sklearn.linear_model import LogisticRegression
model = LogisticRegression()
model.fit(X_train, y_train)
```
# Predicted
```{python}
model.predict(X_test)
```

# Actuals

```{python}
y_test.head()
```

```{python}
model.score(X_train, y_train)
```

* This should be the validation accuracy we are looking for
```{python}
model.score(X_test, y_test)
```

* Apply predictions to actual test data
```{python}
submission4 = test.copy()
```

```{python}
submission4['Cover_Type'] = model.predict(submission4[features_selected])
```

* Write to csv

```{python}
submission4[['Id','Cover_Type']].to_csv('submission4.csv', index=False)
```

```{bash, eval = FALSE}
#kaggle competitions submit favorita-grocery-sales-forecasting -f sample_submission_favorita.csv.7z -m "My submission message"
kaggle competitions submit learn-together -f submission4.csv -m "My 4th submission using test/train split and Logistic Regresion with 3 features"
```

```{bash, eval=FALSE}
# List the submissions to see if they are successful
kaggle competitions submissions learn-together
```

